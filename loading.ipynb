{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from keras import Model\n",
    "from keras.layers import Input, Dense, GRU, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n",
      "3.6.5 (default, Apr  1 2018, 05:46:30) \n",
      "[GCC 7.3.0]\n",
      "sys.version_info(major=3, minor=6, micro=5, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304714"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open('cornell/movie_lines128.txt').read().split('\\n')\n",
    "len(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\"]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_lines = open('cornell/movie_conversations128.txt').read().split('\\n')\n",
    "conv_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "[['L194', 'L195', 'L196', 'L197'], ['L198', 'L199'], ['L200', 'L201', 'L202', 'L203'], ['L204', 'L205', 'L206'], ['L207', 'L208'], ['L271', 'L272', 'L273', 'L274', 'L275'], ['L276', 'L277'], ['L280', 'L281'], ['L363', 'L364'], ['L365', 'L366']]\n"
     ]
    }
   ],
   "source": [
    "id2line = {}\n",
    "for line in lines:\n",
    "    line_list = line.split(' +++$+++ ')\n",
    "    if len(line_list) == 5:\n",
    "        id2line[line_list[0]] = line_list[4]\n",
    "    else :\n",
    "        print(line_list)\n",
    "        \n",
    "convs = []\n",
    "for line in conv_lines[:-1]:\n",
    "    _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \",\"\")\n",
    "    convs.append(_line.split(','))\n",
    "\n",
    "print(convs[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_start = 'ssss '\n",
    "mark_end = ' eeee'\n",
    "input_x = []\n",
    "output_y = []\n",
    "for conv in convs:\n",
    "    for i in range(len(conv) - 1):\n",
    "        input_x.append(id2line[conv[i]])\n",
    "        output_y.append(mark_start+id2line[conv[i+1]]+mark_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "ssss Not the hacking and gagging and spitting part.  Please. eeee\n",
      "Not the hacking and gagging and spitting part.  Please.\n",
      "ssss Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? eeee\n",
      "You're asking me out.  That's so cute. What's your name again?\n",
      "ssss Forget it. eeee\n",
      "No, no, it's my fault -- we didn't have a proper introduction ---\n",
      "ssss Cameron. eeee\n",
      "Cameron.\n",
      "ssss The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. eeee\n",
      "The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n",
      "ssss Seems like she could get a date easy enough... eeee\n",
      "Why?\n",
      "ssss Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something. eeee\n",
      "Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\n",
      "ssss That's a shame. eeee\n",
      "Gosh, if only we could find Kat a boyfriend...\n",
      "ssss Let me see what I can do. eeee\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(input_x[i])\n",
    "    print(output_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"th-at is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well i thought we would start with pronunciation if that is okay with you\n",
      "ssss not the hacking and gagging and spitting part  please eeee\n",
      "not the hacking and gagging and spitting part  please\n",
      "ssss okay then how about we try out some french cuisine  saturday  night eeee\n",
      "you are asking me out  that is so cute that is your name again\n",
      "ssss forget it eeee\n",
      "no no it is my fault  we did not have a proper introduction \n",
      "ssss cameron eeee\n",
      "cameron\n",
      "ssss the thing is cameron  i am at the mercy of a particularly hideous breed of loser  my sister  i cannot date until she does eeee\n",
      "the thing is cameron  i am at the mercy of a particularly hideous breed of loser  my sister  i cannot date until she does\n",
      "ssss seems like she could get a date easy enough eeee\n",
      "why\n",
      "ssss unsolved mystery  she used to be really popular when she started high school then it was just like she got sick of it or something eeee\n",
      "unsolved mystery  she used to be really popular when she started high school then it was just like she got sick of it or something\n",
      "ssss that is a shame eeee\n",
      "gosh if only we could find kat a boyfriend\n",
      "ssss let me see what i can do eeee\n"
     ]
    }
   ],
   "source": [
    "input_x_clean = []\n",
    "for sent in input_x:\n",
    "    input_x_clean.append(clean_text(sent))\n",
    "\n",
    "output_y_clean = []\n",
    "for sent in output_y:\n",
    "    output_y_clean.append(clean_text(sent))\n",
    "    \n",
    "for i in range(1,10):\n",
    "    print(input_x_clean[i])\n",
    "    print(output_y_clean[i])\n",
    "    \n",
    "min_length = 2\n",
    "max_length = 20\n",
    "final_input = []\n",
    "final_output = []\n",
    "for i in range(0,len(input_x_clean)):\n",
    "    temp_input_list = input_x_clean[i].split(' ')\n",
    "    temp_output_list = output_y_clean[i].split(' ')\n",
    "    if len(temp_input_list) > max_length or len(temp_input_list) < min_length  or len(temp_output_list) > max_length or len(temp_output_list) < min_length:\n",
    "        d  = 1 + 1\n",
    "    else:\n",
    "        final_input.append(input_x_clean[i])\n",
    "        final_output.append(output_y_clean[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerWrap(Tokenizer):\n",
    "    \"\"\"Wrap the Tokenizer-class from Keras with more functionality.\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, padding,\n",
    "                 reverse=False, num_words=None):\n",
    "        \"\"\"\n",
    "        :param texts: List of strings. This is the data-set.\n",
    "        :param padding: Either 'post' or 'pre' padding.\n",
    "        :param reverse: Boolean whether to reverse token-lists.\n",
    "        :param num_words: Max number of words to use.\n",
    "        \"\"\"\n",
    "\n",
    "        Tokenizer.__init__(self, num_words=num_words)\n",
    "\n",
    "        # Create the vocabulary from the texts.\n",
    "        self.fit_on_texts(texts)\n",
    "\n",
    "        # Create inverse lookup from integer-tokens to words.\n",
    "        self.index_to_word = dict(zip(self.word_index.values(),\n",
    "                                      self.word_index.keys()))\n",
    "\n",
    "        # Convert all texts to lists of integer-tokens.\n",
    "        # Note that the sequences may have different lengths.\n",
    "        self.tokens = self.texts_to_sequences(texts)\n",
    "\n",
    "        if reverse:\n",
    "            # Reverse the token-sequences.\n",
    "            self.tokens = [list(reversed(x)) for x in self.tokens]\n",
    "        \n",
    "            # Sequences that are too long should now be truncated\n",
    "            # at the beginning, which corresponds to the end of\n",
    "            # the original sequences.\n",
    "            truncating = 'pre'\n",
    "        else:\n",
    "            # Sequences that are too long should be truncated\n",
    "            # at the end.\n",
    "            truncating = 'post'\n",
    "\n",
    "        # The number of integer-tokens in each sequence.\n",
    "        self.num_tokens = [len(x) for x in self.tokens]\n",
    "\n",
    "        # Max number of tokens to use in all sequences.\n",
    "        # We will pad / truncate all sequences to this length.\n",
    "        # This is a compromise so we save a lot of memory and\n",
    "        # only have to truncate maybe 5% of all the sequences.\n",
    "        self.max_tokens = np.mean(self.num_tokens) \\\n",
    "                          + 2 * np.std(self.num_tokens)\n",
    "        self.max_tokens = int(self.max_tokens)\n",
    "\n",
    "        # Pad / truncate all token-sequences to the given length.\n",
    "        # This creates a 2-dim numpy matrix that is easier to use.\n",
    "        self.tokens_padded = pad_sequences(self.tokens,\n",
    "                                           maxlen=self.max_tokens,\n",
    "                                           padding=padding,\n",
    "                                           truncating=truncating)\n",
    "\n",
    "    def token_to_word(self, token):\n",
    "        \"\"\"Lookup a single word from an integer-token.\"\"\"\n",
    "\n",
    "        word = \" \" if token == 0 else self.index_to_word[token]\n",
    "        return word \n",
    "\n",
    "    def tokens_to_string(self, tokens):\n",
    "        \"\"\"Convert a list of integer-tokens to a string.\"\"\"\n",
    "\n",
    "        # Create a list of the individual words.\n",
    "        words = [self.index_to_word[token]\n",
    "                 for token in tokens\n",
    "                 if token != 0]\n",
    "        \n",
    "        # Concatenate the words to a single string\n",
    "        # with space between all the words.\n",
    "        text = \" \".join(words)\n",
    "\n",
    "        return text\n",
    "    \n",
    "    def text_to_tokens(self, text, reverse=False, padding=False):\n",
    "        \"\"\"\n",
    "        Convert a single text-string to tokens with optional\n",
    "        reversal and padding.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert to tokens. Note that we assume there is only\n",
    "        # a single text-string so we wrap it in a list.\n",
    "        tokens = self.texts_to_sequences([text])\n",
    "        tokens = np.array(tokens)\n",
    "\n",
    "        if reverse:\n",
    "            # Reverse the tokens.\n",
    "            tokens = np.flip(tokens, axis=1)\n",
    "\n",
    "            # Sequences that are too long should now be truncated\n",
    "            # at the beginning, which corresponds to the end of\n",
    "            # the original sequences.\n",
    "            truncating = 'pre'\n",
    "        else:\n",
    "            # Sequences that are too long should be truncated\n",
    "            # at the end.\n",
    "            truncating = 'post'\n",
    "\n",
    "        if padding:\n",
    "            # Pad and truncate sequences to the given length.\n",
    "            tokens = pad_sequences(tokens,\n",
    "                                   maxlen=self.max_tokens,\n",
    "                                   padding='pre',\n",
    "                                   truncating=truncating)\n",
    "\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"th-at is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "tokenizer_src = TokenizerWrap(texts = final_input, padding='pre', reverse = True, num_words = num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144852, 16)\n",
      "(144852, 17)\n",
      "2\n",
      "1\n",
      "[  2 275   8   1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[  0   0 156 144  22   4   9 920  42   4   9  46  14 500  11   1]\n",
      "[   2   50   69    3   13  352   26    5 7793    1    0    0    0    0\n",
      "    0    0    0]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0 370  27   4  21 822]\n",
      "(144852, 16)\n",
      "(144852, 16)\n"
     ]
    }
   ],
   "source": [
    "tokenizer_dest = TokenizerWrap(texts = final_output, padding='post', reverse = False, num_words = num_words)\n",
    "tokens_src = tokenizer_src.tokens_padded\n",
    "tokens_dest = tokenizer_dest.tokens_padded\n",
    "print(tokens_src.shape)\n",
    "print(tokens_dest.shape)\n",
    "token_start = tokenizer_dest.word_index[mark_start.strip()]\n",
    "print(token_start)\n",
    "token_end = tokenizer_dest.word_index[mark_end.strip()]\n",
    "print(token_end)\n",
    "print(tokens_dest[2])\n",
    "print(tokens_src[2])\n",
    "print (tokens_dest[5])\n",
    "print(tokens_src[5])\n",
    "encoder_input_data = tokens_src[:,:]\n",
    "decoder_input_data = tokens_dest[:,:-1]\n",
    "decoder_output_data = tokens_dest[:,1:]\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_output_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy loss between y_true and y_pred.\n",
    "    \n",
    "    y_true is a 2-rank tensor with the desired output.\n",
    "    The shape is [batch_size, sequence_length] and it\n",
    "    contains sequences of integer-tokens.\n",
    "\n",
    "    y_pred is the decoder's output which is a 3-rank tensor\n",
    "    with shape [batch_size, sequence_length, num_words]\n",
    "    so that for each sequence in the batch there is a one-hot\n",
    "    encoded array of length num_words.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the loss. This outputs a\n",
    "    # 2-rank tensor of shape [batch_size, sequence_length]\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_true,\n",
    "                                                          logits=y_pred)\n",
    "\n",
    "    # Keras may reduce this across the first axis (the batch)\n",
    "    # but the semantics are unclear, so to be sure we use\n",
    "    # the loss across the entire 2-rank tensor, we reduce it\n",
    "    # to a single scalar with the mean function.\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.losses\n",
    "keras.losses.sparse_cross_entropy = sparse_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('chbot3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, None, 128)    1280000     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru1 (GRU)              (None, None, 512)    984576      encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru2 (GRU)              (None, None, 512)    1574400     encoder_gru1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedding (Embedding)   (None, None, 128)    1280000     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru3 (GRU)              (None, 512)          1574400     encoder_gru2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru1 (GRU)              (None, None, 512)    984576      decoder_embedding[0][0]          \n",
      "                                                                 encoder_gru3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru2 (GRU)              (None, None, 512)    1574400     decoder_gru1[0][0]               \n",
      "                                                                 encoder_gru3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru3 (GRU)              (None, None, 512)    1574400     decoder_gru2[0][0]               \n",
      "                                                                 encoder_gru3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, None, 10000)  5130000     decoder_gru3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 15,956,752\n",
      "Trainable params: 15,956,752\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoder_input', 'decoder_input']\n",
      "['decoder_output']\n",
      "[<keras.engine.input_layer.InputLayer object at 0x7fcad097def0>, <keras.layers.embeddings.Embedding object at 0x7fcad091c5c0>, <keras.layers.recurrent.GRU object at 0x7fcad06fec18>, <keras.engine.input_layer.InputLayer object at 0x7fcad097f7f0>, <keras.layers.recurrent.GRU object at 0x7fcad0662550>, <keras.layers.embeddings.Embedding object at 0x7fcacd4656d8>, <keras.layers.recurrent.GRU object at 0x7fcacd465b70>, <keras.layers.recurrent.GRU object at 0x7fcacd465a90>, <keras.layers.recurrent.GRU object at 0x7fcacd4650f0>, <keras.layers.recurrent.GRU object at 0x7fcacd465208>, <keras.layers.core.Dense object at 0x7fcacd465438>]\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fcad097def0>\n",
      "<keras.layers.embeddings.Embedding object at 0x7fcad091c5c0>\n",
      "Tensor(\"decoder_input_14:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(model.input_names)\n",
    "print(model.output_names)\n",
    "print(model.layers)\n",
    "print (model.layers[0])\n",
    "print (model.layers[1])\n",
    "print (model.inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "encoder_input = model.input[0]\n",
    "encoder_output = model.layers[6].output\n",
    "model_encoder = Model(input=[encoder_input], outputs = [encoder_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, None)              0         \n",
      "_________________________________________________________________\n",
      "encoder_embedding (Embedding (None, None, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "encoder_gru1 (GRU)           (None, None, 512)         984576    \n",
      "_________________________________________________________________\n",
      "encoder_gru2 (GRU)           (None, None, 512)         1574400   \n",
      "_________________________________________________________________\n",
      "encoder_gru3 (GRU)           (None, 512)               1574400   \n",
      "=================================================================\n",
      "Total params: 5,413,376\n",
      "Trainable params: 5,413,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = 512\n",
    "decoder_input = model.inputs[1]\n",
    "decoder_initial_state = Input(shape=(state_size,),name = 'decoder_initial_state')\n",
    "decoder_embedding = model.layers[5]\n",
    "decoder_gru1 = model.layers[7]\n",
    "decoder_gru2 = model.layers[8]\n",
    "decoder_gru3 = model.layers[9]\n",
    "decoder_dense = model.layers[10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = decoder_input\n",
    "net = decoder_embedding(net)\n",
    "net = decoder_gru1(net, initial_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = decoder_gru2(net, initial_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = decoder_gru3(net, initial_state=decoder_initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = decoder_dense(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_decoder = Model(inputs=[decoder_input, decoder_initial_state], outputs = [decoder_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedding (Embedding)   (None, None, 128)    1280000     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_initial_state (InputLay (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru1 (GRU)              (None, None, 512)    984576      decoder_embedding[1][0]          \n",
      "                                                                 decoder_initial_state[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru2 (GRU)              (None, None, 512)    1574400     decoder_gru1[1][0]               \n",
      "                                                                 decoder_initial_state[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru3 (GRU)              (None, None, 512)    1574400     decoder_gru2[1][0]               \n",
      "                                                                 decoder_initial_state[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, None, 10000)  5130000     decoder_gru3[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,543,376\n",
      "Trainable params: 10,543,376\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_text, true_output_text=None):\n",
    "    \"\"\"Translate a single text-string.\"\"\"\n",
    "\n",
    "    # Convert the input-text to integer-tokens.\n",
    "    # Note the sequence of tokens has to be reversed.\n",
    "    # Padding is probably not necessary.\n",
    "    input_tokens = tokenizer_src.text_to_tokens(text=input_text,\n",
    "                                                reverse=True,\n",
    "                                                padding=True)\n",
    "    \n",
    "    # Get the output of the encoder's GRU which will be\n",
    "    # used as the initial state in the decoder's GRU.\n",
    "    # This could also have been the encoder's final state\n",
    "    # but that is really only necessary if the encoder\n",
    "    # and decoder use the LSTM instead of GRU because\n",
    "    # the LSTM has two internal states.\n",
    "    initial_state = model_encoder.predict(input_tokens)\n",
    "\n",
    "    # Max number of tokens / words in the output sequence.\n",
    "    max_tokens = tokenizer_dest.max_tokens\n",
    "\n",
    "    # Pre-allocate the 2-dim array used as input to the decoder.\n",
    "    # This holds just a single sequence of integer-tokens,\n",
    "    # but the decoder-model expects a batch of sequences.\n",
    "    shape = (1, max_tokens)\n",
    "    decoder_input_data = np.zeros(shape=shape, dtype=np.int)\n",
    "\n",
    "    # The first input-token is the special start-token for 'ssss '.\n",
    "    token_int = token_start\n",
    "\n",
    "    # Initialize an empty output-text.\n",
    "    output_text = ''\n",
    "\n",
    "    # Initialize the number of tokens we have processed.\n",
    "    count_tokens = 0\n",
    "\n",
    "    # While we haven't sampled the special end-token for ' eeee'\n",
    "    # and we haven't processed the max number of tokens.\n",
    "    while token_int != token_end and count_tokens < max_tokens:\n",
    "        # Update the input-sequence to the decoder\n",
    "        # with the last token that was sampled.\n",
    "        # In the first iteration this will set the\n",
    "        # first element to the start-token.\n",
    "        decoder_input_data[0, count_tokens] = token_int\n",
    "\n",
    "        # Wrap the input-data in a dict for clarity and safety,\n",
    "        # so we are sure we input the data in the right order.\n",
    "        x_data = \\\n",
    "        {\n",
    "            'decoder_initial_state': initial_state,\n",
    "            'decoder_input': decoder_input_data\n",
    "        }\n",
    "\n",
    "        # Note that we input the entire sequence of tokens\n",
    "        # to the decoder. This wastes a lot of computation\n",
    "        # because we are only interested in the last input\n",
    "        # and output. We could modify the code to return\n",
    "        # the GRU-states when calling predict() and then\n",
    "        # feeding these GRU-states as well the next time\n",
    "        # we call predict(), but it would make the code\n",
    "        # much more complicated.\n",
    "\n",
    "        # Input this data to the decoder and get the predicted output.\n",
    "        decoder_output = model_decoder.predict(x_data)\n",
    "\n",
    "        # Get the last predicted token as a one-hot encoded array.\n",
    "        token_onehot = decoder_output[0, count_tokens, :]\n",
    "        \n",
    "        # Convert to an integer-token.\n",
    "        token_int = np.argmax(token_onehot)\n",
    "\n",
    "        # Lookup the word corresponding to this integer-token.\n",
    "        sampled_word = tokenizer_dest.token_to_word(token_int)\n",
    "\n",
    "        # Append the word to the output-text.\n",
    "        output_text += \" \" + sampled_word\n",
    "\n",
    "        # Increment the token-counter.\n",
    "        count_tokens += 1\n",
    "\n",
    "    # Sequence of tokens output by the decoder.\n",
    "    output_tokens = decoder_input_data[0]\n",
    "    \n",
    "    # Print the input-text.\n",
    "    print(\"Input text:\")\n",
    "    print(input_text)\n",
    "    print()\n",
    "\n",
    "    # Print the translated output-text.\n",
    "    print(\"Translated text:\")\n",
    "    print(output_text)\n",
    "    print()\n",
    "\n",
    "    # Optionally print the true translated text.\n",
    "    if true_output_text is not None:\n",
    "        print(\"True output text:\")\n",
    "        print(true_output_text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "how are you.\n",
      "\n",
      "Translated text:\n",
      " fine fine eeee\n",
      "\n",
      "Input text:\n",
      "what are you doing\n",
      "\n",
      "Translated text:\n",
      " i am going in i have to think you were just movie eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translate(input_text=\"how are you.\")\n",
    "translate(input_text=\"what are you doing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "Do you love me\n",
      "\n",
      "Translated text:\n",
      " i asked you too eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translate(input_text = \"Do you love me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "what is your name\n",
      "\n",
      "Translated text:\n",
      " my name is sir sir of eeee\n",
      "\n",
      "Input text:\n",
      "how are you\n",
      "\n",
      "Translated text:\n",
      " fine fine eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translate(input_text = \"what is your name\")\n",
    "translate(input_text = \"how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "Do you like me\n",
      "\n",
      "Translated text:\n",
      " yes i like you eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translate(input_text = \"Do you like me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "where do you live\n",
      "\n",
      "Translated text:\n",
      " excuse me eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translate(input_text = \"where do you live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "lets go out today\n",
      "\n",
      "Translated text:\n",
      " uhhuh how many i would not do it eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translate(input_text = \"lets go out today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "can i visit you today\n",
      "\n",
      "Translated text:\n",
      " yeah sure eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translate(input_text = \"can i visit you today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "what will you eat today\n",
      "\n",
      "Translated text:\n",
      " a coke eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translate(input_text=\"what will you eat today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
